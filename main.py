import cv2
import os
import numpy as np
from PIL import Image
import torch
from segment_anything import sam_model_registry, SamPredictor
import time
from datetime import datetime
import yaml
print("PyTorch ç‰ˆæœ¬:", torch.__version__)
print("CUDA å¯ç”¨:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("CUDA ç‰ˆæœ¬:", torch.version.cuda)
    print("cuDNN ç‰ˆæœ¬:", torch.backends.cudnn.version())
    print("GPU æ•¸é‡:", torch.cuda.device_count())
    print("GPU åç¨±:", torch.cuda.get_device_name(0))




### è¼‰å…¥é…ç½®æ–‡ä»¶
def load_config(config_path="config.yaml"):
    """è¼‰å…¥ YAML é…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as file:
            config = yaml.safe_load(file)
        print(f"âœ… æˆåŠŸè¼‰å…¥é…ç½®æ–‡ä»¶: {config_path}")
        return config
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {config_path}")
        print("æ­£åœ¨å‰µå»ºé è¨­é…ç½®æ–‡ä»¶...")
        create_default_config(config_path)
        return load_config(config_path)
    except yaml.YAMLError as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼éŒ¯èª¤: {e}")
        raise

def create_default_config(config_path="config.yaml"):
    """å‰µå»ºé è¨­é…ç½®æ–‡ä»¶"""
    default_config = {
        'paths': {
            'video_path': 'D:/project/diffusion/vedio/test.mp4',
            'frames_dir': 'frames',
            'masks_dir': 'masks',
            'recolored_dir': 'recolored_frames',
            'output_video': 'output_video.mp4'
        },
        'sam': {
            'model_type': 'vit_b',
            'checkpoint_path': 'sam_model/sam_vit_b_01ec64.pth'
        },
        'processing': {
            'target_color': [0, 0, 0],
            'video_codec': 'mp4v',
            'use_cuda': True
        },
        'display': {
            'progress_interval': 30,
            'show_preview': True,
            'window_title': 'è«‹é»é¸ç›®æ¨™ç‰©ä»¶ (é»é¸å¾ŒæŒ‰ä»»æ„éµ)'
        },
        'optimization': {
            'batch_size': 1,
            'memory_limit_gb': 8
        },
        'output': {
            'preserve_fps': True,
            'quality': 'high'
        },
        'debug': {
            'verbose': True,
            'save_intermediate': True,
            'log_timing': True
        }
    }
    
    with open(config_path, 'w', encoding='utf-8') as file:
        yaml.dump(default_config, file, default_flow_style=False, allow_unicode=True, indent=2)
    print(f"âœ… å·²å‰µå»ºé è¨­é…ç½®æ–‡ä»¶: {config_path}")

### æ€§èƒ½ç›£æ¸¬è£é£¾å™¨
def time_it(func_name, config):
    def decorator(func):
        def wrapper(*args, **kwargs):
            if not config['debug']['log_timing']:
                return func(*args, **kwargs)
                
            start_time = time.time()
            if config['debug']['verbose']:
                print(f"â±ï¸ é–‹å§‹åŸ·è¡Œ {func_name}...")
            
            result = func(*args, **kwargs)
            
            end_time = time.time()
            elapsed = end_time - start_time
            if config['debug']['verbose']:
                print(f"âœ… {func_name} å®Œæˆ - è€—æ™‚: {elapsed:.2f} ç§’")
            return result
        return wrapper
    return decorator

# å…¨åŸŸé…ç½®
CONFIG = load_config()

# è¨­å‚™æª¢æ¸¬
use_cuda = CONFIG['processing']['use_cuda'] and torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
if CONFIG['debug']['verbose']:
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {device}")
    if use_cuda:
        print(f"   GPU: {torch.cuda.get_device_name(0)}")

# è¨­å®šåƒæ•¸é¡åˆ¥ (ç‚ºäº†å‘ä¸‹ç›¸å®¹)
class Config:
    def __init__(self, config_dict):
        # è·¯å¾‘è¨­å®š
        self.VIDEO_PATH = config_dict['paths']['video_path']
        self.FRAMES_DIR = config_dict['paths']['frames_dir']
        self.MASKS_DIR = config_dict['paths']['masks_dir']
        self.RECOLORED_DIR = config_dict['paths']['recolored_dir']
        self.OUTPUT_VIDEO = config_dict['paths']['output_video']
        
        # SAM è¨­å®š
        self.MODEL_TYPE = config_dict['sam']['model_type']
        self.CHECKPOINT_PATH = config_dict['sam']['checkpoint_path']
        
        # è™•ç†è¨­å®š
        self.TARGET_COLOR = config_dict['processing']['target_color']
        self.VIDEO_CODEC = config_dict['processing']['video_codec']
        
        # é¡¯ç¤ºè¨­å®š
        self.PROGRESS_INTERVAL = config_dict['display']['progress_interval']
        self.WINDOW_TITLE = config_dict['display']['window_title']
        self.SHOW_PREVIEW = config_dict['display']['show_preview']

# åˆå§‹åŒ–é…ç½®å¯¦ä¾‹
config = Config(CONFIG)

# å‰µå»ºå¿…è¦çš„ç›®éŒ„
def setup_directories():
    dirs = [config.FRAMES_DIR, config.MASKS_DIR, config.RECOLORED_DIR]
    for dir_path in dirs:
        os.makedirs(dir_path, exist_ok=True)
    if CONFIG['debug']['verbose']:
        print("ğŸ“ ç›®éŒ„è¨­ç½®å®Œæˆ")

# Step 1. å½±ç‰‡è½‰æˆå¹€
@time_it("æå–å¹€", CONFIG)
def extract_frames(video_path):
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°è¦–é »æ–‡ä»¶: {video_path}")
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("âŒ ç„¡æ³•æ‰“é–‹è¦–é »æ–‡ä»¶")
    
    # ç²å–è¦–é »è³‡è¨Š
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    
    if CONFIG['debug']['verbose']:
        print(f"ğŸ“¹ è¦–é »è³‡è¨Š:")
        print(f"   - FPS: {fps:.2f}")
        print(f"   - ç¸½å¹€æ•¸: {total_frames}")
        print(f"   - æ™‚é•·: {duration:.2f} ç§’")
    
    idx = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        cv2.imwrite(f"{config.FRAMES_DIR}/frame_{idx:04d}.jpg", frame)
        idx += 1
        
        # é¡¯ç¤ºé€²åº¦
        if CONFIG['debug']['verbose'] and idx % CONFIG['display']['progress_interval'] == 0:
            progress = (idx / total_frames) * 100
            print(f"   é€²åº¦: {progress:.1f}% ({idx}/{total_frames})")
    
    cap.release()
    if CONFIG['debug']['verbose']:
        print(f"âœ… æˆåŠŸæå– {idx} å¹€")
    return fps  # è¿”å›fpsä¾›å¾ŒçºŒä½¿ç”¨

# Step 2. SAM åˆ†å‰²
@time_it("SAM ç‰©ä»¶åˆ†å‰²", CONFIG)
def sam_segment(frame_path, checkpoint):
    if not os.path.exists(checkpoint):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ° SAM æ¨¡å‹æ–‡ä»¶: {checkpoint}")
    
    if CONFIG['debug']['verbose']:
        print("ğŸ¤– æ­£åœ¨è¼‰å…¥ SAM æ¨¡å‹...")
    sam = sam_model_registry[config.MODEL_TYPE](checkpoint=checkpoint)
    if use_cuda:
        sam = sam.cuda()
    predictor = SamPredictor(sam)

    image = cv2.imread(frame_path)
    if image is None:
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å¹€æ–‡ä»¶: {frame_path}")
    
    predictor.set_image(image)

    # äº’å‹•å¼é»é¸
    click_coords = []
    window_name = config.WINDOW_TITLE

    def mouse_callback(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            click_coords.append((x, y))
            if CONFIG['debug']['verbose']:
                print(f"ğŸ–±ï¸ é»é¸ä½ç½®: ({x}, {y})")
            # åœ¨åœ–åƒä¸Šæ¨™è¨˜é»é¸ä½ç½®
            cv2.circle(image, (x, y), 5, (0, 255, 0), -1)
            cv2.imshow(window_name, image)

    cv2.namedWindow(window_name)
    cv2.setMouseCallback(window_name, mouse_callback)
    cv2.imshow(window_name, image)
    
    if CONFIG['debug']['verbose']:
        print("ğŸ–±ï¸ è«‹åœ¨åœ–åƒä¸Šé»é¸è¦è™•ç†çš„ç‰©ä»¶...")
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    if not click_coords:
        raise ValueError("âŒ æ²’æœ‰é»é¸ä»»ä½•ä½ç½®ï¼Œç¨‹å¼çµ‚æ­¢")

    input_point = np.array([click_coords[0]])
    input_label = np.array([1])

    if CONFIG['debug']['verbose']:
        print("ğŸ” æ­£åœ¨ç”Ÿæˆåˆ†å‰²é®ç½©...")
    masks, scores, _ = predictor.predict(
        point_coords=input_point,
        point_labels=input_label,
        multimask_output=False
    )

    mask = masks[0]
    
    # é¡¯ç¤ºåˆ†å‰²çµæœä¾›ç¢ºèª
    if config.SHOW_PREVIEW:
        masked_image = image.copy()
        masked_image[mask] = masked_image[mask] * 0.5 + np.array([0, 255, 0]) * 0.5
        cv2.imshow("åˆ†å‰²çµæœé è¦½ (æŒ‰ä»»æ„éµç¹¼çºŒ)", masked_image.astype(np.uint8))
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    
    cv2.imwrite(f"{config.MASKS_DIR}/mask_0000.png", mask.astype(np.uint8) * 255)
    if CONFIG['debug']['verbose']:
        print(f"âœ… åˆ†å‰²å®Œæˆï¼Œç½®ä¿¡åº¦: {scores[0]:.3f}")
    return mask

@time_it("è¿½è¹¤èˆ‡é®ç½©å‚³æ’­", CONFIG)
def track_and_propagate_mask(initial_mask, num_frames):
    tracker = cv2.TrackerCSRT_create()

    # è®€å–åˆå§‹ frame & é®ç½©
    init_frame_path = f"{config.FRAMES_DIR}/frame_0000.jpg"
    frame = cv2.imread(init_frame_path)
    mask = initial_mask.astype(np.uint8) * 255

    # æ¨æ¸¬åˆå§‹é®ç½© bounding box
    x, y, w, h = cv2.boundingRect(mask)

    # åˆå§‹åŒ–è¿½è¹¤å™¨
    tracker.init(frame, (x, y, w, h))

    for i in range(num_frames):
        frame_path = f"{config.FRAMES_DIR}/frame_{i:04d}.jpg"
        frame = cv2.imread(frame_path)

        success, box = tracker.update(frame)
        if not success:
            print(f"âš ï¸ ç¬¬{i}å¹€è¿½è¹¤å¤±æ•—")
            continue

        x, y, w, h = [int(v) for v in box]

        # å°‡åˆå§‹é®ç½©è²¼åˆ°æ–°ä½ç½®
        new_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)
        mask_crop = mask[y:y+h, x:x+w]
        new_mask[y:y+h, x:x+w] = mask_crop

        out_path = f"{config.MASKS_DIR}/mask_{i:04d}.png"
        cv2.imwrite(out_path, new_mask)
        
        if CONFIG['debug']['verbose'] and i % 30 == 0:
            print(f"   å¹€ {i}: è¿½è¹¤ä½ç½® ({x}, {y}, {w}, {h})")

    print("âœ… é®ç½©è¿½è¹¤èˆ‡å‚³æ’­å®Œæˆ")

# Step 4. é‡æ–°è‘—è‰²
@time_it("ç‰©ä»¶é‡æ–°è‘—è‰²", CONFIG)
def recolor_object(target_color=None):
    if target_color is None:
        target_color = config.TARGET_COLOR
    
    frame_files = sorted([f for f in os.listdir(config.FRAMES_DIR) if f.endswith('.jpg')])
    total_frames = len(frame_files)
    
    if CONFIG['debug']['verbose']:
        print(f"ğŸ¨ æ­£åœ¨é‡æ–°è‘—è‰² {total_frames} å¹€...")
    
    for idx, fname in enumerate(frame_files):
        frame_path = os.path.join(config.FRAMES_DIR, fname)
        mask_path = f"{config.MASKS_DIR}/mask_{idx:04d}.png"
        
        if not os.path.exists(mask_path):
            if CONFIG['debug']['verbose']:
                print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°é®ç½©æ–‡ä»¶ {mask_path}")
            continue
            
        frame = cv2.imread(frame_path)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        
        if frame is None or mask is None:
            if CONFIG['debug']['verbose']:
                print(f"âš ï¸ è­¦å‘Š: ç„¡æ³•è®€å–æ–‡ä»¶ - frame: {frame_path}, mask: {mask_path}")
            continue
            
        mask_binary = mask > 128
        
        # æ‡‰ç”¨æ–°é¡è‰²
        frame[mask_binary] = target_color
        
        output_path = f"{config.RECOLORED_DIR}/frame_{idx:04d}.jpg"
        cv2.imwrite(output_path, frame)
        
        # é¡¯ç¤ºé€²åº¦
        if CONFIG['debug']['verbose'] and (idx + 1) % CONFIG['display']['progress_interval'] == 0:
            progress = ((idx + 1) / total_frames) * 100
            print(f"   é€²åº¦: {progress:.1f}% ({idx + 1}/{total_frames})")
    
    if CONFIG['debug']['verbose']:
        print("âœ… é‡æ–°è‘—è‰²å®Œæˆ")

# Step 5. åˆæˆè¦–é »
@time_it("åˆæˆè¼¸å‡ºè¦–é »", CONFIG)
def build_video_from_frames(fps=30):
    frame_files = sorted([f for f in os.listdir(config.RECOLORED_DIR) if f.endswith('.jpg')])
    
    if not frame_files:
        raise FileNotFoundError("âŒ æ‰¾ä¸åˆ°é‡æ–°è‘—è‰²çš„å¹€æ–‡ä»¶")

    first_frame = cv2.imread(os.path.join(config.RECOLORED_DIR, frame_files[0]))
    if first_frame is None:
        raise ValueError("âŒ ç„¡æ³•è®€å–ç¬¬ä¸€å¹€")
    
    h, w, _ = first_frame.shape
    if CONFIG['debug']['verbose']:
        print(f"ğŸ“¹ è¼¸å‡ºè¦–é »è¦æ ¼: {w}x{h} @ {fps}fps")

    # ä½¿ç”¨é…ç½®ä¸­çš„ç·¨ç¢¼å™¨
    fourcc = cv2.VideoWriter_fourcc(*config.VIDEO_CODEC)
    out = cv2.VideoWriter(config.OUTPUT_VIDEO, fourcc, fps, (w, h))
    
    total_frames = len(frame_files)
    for idx, frame_name in enumerate(frame_files):
        frame_path = os.path.join(config.RECOLORED_DIR, frame_name)
        frame = cv2.imread(frame_path)
        
        if frame is None:
            if CONFIG['debug']['verbose']:
                print(f"âš ï¸ è­¦å‘Š: ç„¡æ³•è®€å–å¹€ {frame_path}")
            continue
            
        out.write(frame)
        
        # é¡¯ç¤ºé€²åº¦
        if CONFIG['debug']['verbose'] and (idx + 1) % CONFIG['display']['progress_interval'] == 0:
            progress = ((idx + 1) / total_frames) * 100
            print(f"   é€²åº¦: {progress:.1f}% ({idx + 1}/{total_frames})")
    
    out.release()
    if CONFIG['debug']['verbose']:
        print(f"âœ… è¼¸å‡ºè¦–é »å·²ä¿å­˜: {config.OUTPUT_VIDEO}")

# ğŸš€ ä¸»æµç¨‹
@time_it("æ•´é«”è™•ç†", CONFIG)
def main():
    try:
        if CONFIG['debug']['verbose']:
            print(f"ğŸš€ é–‹å§‹è™•ç†è¦–é »: {config.VIDEO_PATH}")
            print(f"â° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # è¨­ç½®ç›®éŒ„
        setup_directories()
        
        # æå–å¹€
        fps = extract_frames(config.VIDEO_PATH)
        
        # SAM åˆ†å‰²
        mask = sam_segment(f"{config.FRAMES_DIR}/frame_0000.jpg", config.CHECKPOINT_PATH)
        
        # é®ç½©å‚³æ’­
        num_frames = len([f for f in os.listdir(config.FRAMES_DIR) if f.endswith('.jpg')])
        track_and_propagate_mask(mask, num_frames)
        
        # é‡æ–°è‘—è‰²
        recolor_object()
        
        # åˆæˆè¦–é » - ä½¿ç”¨åŸå§‹FPSæˆ–é è¨­å€¼
        output_fps = fps if CONFIG['output']['preserve_fps'] else 30
        build_video_from_frames(output_fps)
        
        if CONFIG['debug']['verbose']:
            print(f"ğŸ‰ æ‰€æœ‰è™•ç†å®Œæˆï¼")
            print(f"â° çµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        raise

if __name__ == "__main__":
    main()
    
# import cv2
# print(hasattr(cv2, 'TrackerCSRT_create'))  # æ‡‰è©²æœƒè¼¸å‡º True
